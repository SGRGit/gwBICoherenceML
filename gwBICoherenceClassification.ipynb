{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gwBICoherenceClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6bHT3ZDzB/bUTxCYlBBgR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SGRGit/gwBICoherenceML/blob/draft/gwBICoherenceClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pNhhtGxencR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "172d4388-b9ed-44ad-ce29-c5801afafc35"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8rLEoDHpcxu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "198dc9c9-b97f-4270-9b44-4b1de1256fa0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aykw4W6Zpgcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/Colab Notebooks')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNxenzR4ptaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "base_dir = \"gdrive/My Drive/Colab Notebooks/gwBICoherenceFiles/\"\n",
        "seta = 'BBH'\n",
        "setb = 'Glitch'\n",
        "\n",
        "data_dir = os.path.join(base_dir, 'Data')\n",
        "seta_data_dir = os.path.join(data_dir, seta)\n",
        "seta_data_fnnames = os.listdir(seta_data_dir)\n",
        "\n",
        "setb_data_dir = os.path.join(data_dir, setb)\n",
        "setb_data_fnnames = os.listdir(setb_data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFZO2sgUqK7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a474d11-bea1-4da4-ed88-4c6a440d8bf1"
      },
      "source": [
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras import regularizers\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxC458VhqT_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "q1 = np.empty((1, 150, 150, 3))\n",
        "q2 = np.empty((1, 150, 150, 3))\n",
        "for a in range(1, len(seta_data_fnnames), 1):\n",
        "  img_path_a = os.path.join(seta_data_dir, seta_data_fnnames[a])\n",
        "  img_a = cv2.imread(os.path.join(seta_data_dir, seta_data_fnnames[a]))\n",
        "  img_a = cv2.resize(img_a, (150, 150))\n",
        "  q1 = np.vstack((q1, img_to_array(img_a).reshape(1, 150, 150, 3)))\n",
        "  t1 = np.ones([len(seta_data_fnnames),1])\n",
        "  \n",
        "for b in range(1, len(setb_data_fnnames), 1):\n",
        "  img_path_b = os.path.join(setb_data_dir, setb_data_fnnames[b])\n",
        "  img_b = cv2.imread(os.path.join(setb_data_dir, setb_data_fnnames[b]))\n",
        "  img_b = cv2.resize(img_b, (150, 150))\n",
        "  q2 = np.vstack((q2, img_to_array(img_b).reshape(1, 150, 150, 3)))\n",
        "  t2 = np.zeros([len(setb_data_fnnames),1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFdpPBkdqmc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = np.vstack((t1, t2))\n",
        "q = np.vstack((q1, q2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8r7k8ikvoVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b45e1837-cc2e-4c57-bdc7-8a288faaab36"
      },
      "source": [
        "len(t)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2652"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyG8mC2-vr_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(q, t, test_size=0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoBQrp8jvwCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Tensorflow Libraries\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from keras import regularizers\n",
        "\n",
        "img_input = layers.Input(shape=(150, 150, 3))\n",
        "\n",
        "# 2D Conv Layer with 64 filters of dimension 3x3 and ReLU activation function\n",
        "x = layers.Conv2D(64, 3, activation = 'relu')(img_input)\n",
        "# 2D Max Pooling Layer\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "# 2D Conv Layer with 128 filters of dimension 3x3 and ReLU activation function\n",
        "x = layers.Conv2D(128, 3, activation = 'relu')(x)\n",
        "# 2D Max Pooling Layer\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "# 2D Conv Layer with 256 filters of dimension 3x3 and ReLU activation function\n",
        "x = layers.Conv2D(256, 3, activation = 'relu')(x)\n",
        "# 2D Max Pooling Layer\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "# 2D Conv Layer with 512 filters of dimension 3x3 and ReLU activation function\n",
        "x = layers.Conv2D(512, 3, activation = 'relu')(x)\n",
        "# 2D Max Pooling Layer\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "# 2D Conv Layer with 512 filters of dimension 3x3 and ReLU activation function\n",
        "x = layers.Conv2D(512, 3, activation = 'relu')(x)\n",
        "\n",
        "# Faltten Layer\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "# Fully Connected Layers and ReLU activation algoritm\n",
        "x = layers.Dense(4096, activation = 'relu')(x)\n",
        "x = layers.Dense(4096, activation = 'relu')(x)\n",
        "x = layers.Dense(1000, activation = 'relu')(x)\n",
        "\n",
        "# Dropout Layer for Optimization\n",
        "#x = layers.Dropout(0.5,noise_shape=None, seed=None)(x)\n",
        "\n",
        "# Fully connected layers and sigmoid activation algorithm\n",
        "output = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "\n",
        "model = Model(img_input, output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPWyrJwdv4QL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "16cfb8ff-0b50-4567-d892-48bc83694eb9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 148, 148, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 74, 74, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 72, 72, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 36, 36, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 34, 34, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 15, 15, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4096)              52432896  \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 1001      \n",
            "=================================================================\n",
            "Total params: 77,222,993\n",
            "Trainable params: 77,222,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgfuAW5pv87h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "             optimizer = tf.train.AdamOptimizer(learning_rate = 0.005),\n",
        "             metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDifOt0fwAkZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7bd234e7-d25c-47e1-f647-9b9532f03943"
      },
      "source": [
        "# Train model (use 10% of training set as validation set)\n",
        "#model.fit(X_train, y_train, validation_split=0.1, epochs=5, batch_size=10, verbose=2)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=5,\n",
        "    batch_size=256,\n",
        "    validation_split=0.1,\n",
        "    verbose = 1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Train model (use validation data as validation set)\n",
        "#model.fit(X_train, Y_train, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1908 samples, validate on 213 samples\n",
            "Epoch 1/5\n",
            "1908/1908 [==============================] - 342s 179ms/sample - loss: 484885.9273 - acc: 0.4832 - val_loss: 12684.2158 - val_acc: 0.4836\n",
            "Epoch 2/5\n",
            " 256/1908 [===>..........................] - ETA: 4:39 - loss: 11953.8281 - acc: 0.5117"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNuimKx4wFIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}